{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from models import *\n",
    "from fid import get_fid\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_models = ['mnist_dcgan/G_10.pth', 'mnist_bigan/G_10.pth', 'mnist_logan_b/G_10.pth']\n",
    "E_models = ['mnist_dcgan/Epost_1.pth', 'mnist_bigan/Epost_1.pth', 'mnist_logan_b/E_10.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='.', download=True, transform=Compose([Resize(32), ToTensor(), Normalize((0.5,),(0.5,))]))\n",
    "dataloader = DataLoader(dataset, batch_size=num_images, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID with 200 images from each distribution\n",
      "FID calculation time: 31.013670 s\n",
      "mnist_dcgan/G_10.pth 71.681656\n",
      "Calculating FID with 200 images from each distribution\n",
      "FID calculation time: 30.933452 s\n",
      "mnist_bigan/G_10.pth 431.01556\n",
      "Calculating FID with 200 images from each distribution\n",
      "FID calculation time: 30.719359 s\n",
      "mnist_logan_b/G_10.pth 40.24572\n"
     ]
    }
   ],
   "source": [
    "for (G_file, E_file) in zip(G_models, E_models):\n",
    "    G = torch.load(G_file).to('cuda:1').eval()\n",
    "    E = torch.load(E_file).to('cuda:1').eval()\n",
    "    \n",
    "    images1 = np.zeros((num_images, 3, 32, 32))\n",
    "    images2 = np.zeros((num_images, 3, 32, 32))\n",
    "    \n",
    "    real = ((next(iter(dataloader))[0]+1)*127).squeeze().numpy()\n",
    "    images1[:,0,:,:] = real.copy()\n",
    "    images1[:,1,:,:] = real.copy()\n",
    "    images1[:,2,:,:] = real.copy()\n",
    "    images1 = images1.astype(np.uint8)\n",
    "    \n",
    "    real = next(iter(dataloader))[0]\n",
    "    latents = E(real.to('cuda:1')).detach()\n",
    "    recon = ((G(latents).cpu().detach()+1)*127).squeeze().numpy()\n",
    "    images2[:,0,:,:] = recon.copy()\n",
    "    images2[:,1,:,:] = recon.copy()\n",
    "    images2[:,2,:,:] = recon.copy()\n",
    "    images2 = images2.astype(np.uint8)\n",
    "    \n",
    "    print(G_file, get_fid(images1, images2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
